{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "# https://archive.ics.uci.edu/dataset/186/wine+quality\n",
    "online_retail = fetch_ucirepo(id=186) \n",
    "  \n",
    "# dataset (as pandas dataframes) \n",
    "X = online_retail.data.features \n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping some columns to reduce the dimensionality of the data\n",
    "X = X.drop(columns=['fixed_acidity', 'volatile_acidity', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'sulphates'])\n",
    "# Storing the remaining feature names\n",
    "features = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataframe to understand the structure of the data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the dataframe to understand the number of rows and columns\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataframe to a numpy array\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KMeans from sklearn.cluster for clustering\n",
    "from sklearn.cluster import KMeans\n",
    "# Importing matplotlib.pyplot for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Initializing KMeans with 3 clusters and a random state of 42 for reproducibility\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# StandardScaler will scale the data to have mean 0 and standard deviation 1\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# MinMaxScaler will scale the data to a given range (default is 0 to 1)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# MaxAbsScaler will scale the data to the range [-1, 1] based on the maximum absolute value\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# scaler = MaxAbsScaler()\n",
    "\n",
    "# Xscaled = scaler.fit_transform(X)\n",
    "\n",
    "Xscaled = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the KMeans model to the scaled data\n",
    "kmeans.fit(Xscaled)\n",
    "# Retrieve the cluster labels assigned to each data point\n",
    "labels = kmeans.labels_\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of subplots with dimensions based on the number of features\n",
    "fig, axes = plt.subplots(len(features), len(features), figsize=(20, 20))\n",
    "# Iterate over each feature for the x-axis\n",
    "for i in range(len(features)):\n",
    "  # Iterate over each feature for the y-axis\n",
    "  for j in range(len(features)):\n",
    "    # Check if the current subplot is not on the diagonal\n",
    "    if i != j:\n",
    "      # Scatter plot of the data points for the i-th and j-th features, colored by cluster labels\n",
    "      axes[i, j].scatter(Xscaled[:, i], Xscaled[:, j], c=labels, cmap='viridis', s=10)\n",
    "      # Set the x-axis label to the i-th feature name\n",
    "      axes[i, j].set_xlabel(features[i])\n",
    "      # Set the y-axis label to the j-th feature name\n",
    "      axes[i, j].set_ylabel(features[j])\n",
    "      # Set the title of the subplot to show the i-th feature vs the j-th feature\n",
    "      axes[i, j].set_title(f'{features[i]} vs {features[j]}')\n",
    "    else:\n",
    "      # Turn off the axis for the diagonal subplots\n",
    "      axes[i, j].axis('off')\n",
    "# Adjust the layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the silhouette_score function from sklearn.metrics\n",
    "from sklearn.metrics import silhouette_score  \n",
    "\n",
    "# Determine the optimal number of clusters using the silhouette score\n",
    "range_n_clusters = list(range(2, 11))  # Define a range of cluster numbers to evaluate, from 2 to 10\n",
    "best_n_clusters = 2  # Initialize the best number of clusters with the minimum value in the range\n",
    "best_silhouette_score = -1  # Initialize the best silhouette score with a very low value\n",
    "\n",
    "for n_clusters in range_n_clusters:  # Iterate over the range of cluster numbers\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)  # Initialize KMeans with the current number of clusters\n",
    "    kmeans.fit(Xscaled)  # Fit the KMeans model to the scaled data\n",
    "    cluster_labels = kmeans.labels_  # Retrieve the cluster labels assigned to each data point\n",
    "    silhouette_avg = silhouette_score(Xscaled, cluster_labels)  # Calculate the average silhouette score for the current clustering\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette_score is : {silhouette_avg}\")  # Print the silhouette score for the current number of clusters\n",
    "    if silhouette_avg > best_silhouette_score:  # Check if the current silhouette score is better than the best one found so far\n",
    "        best_silhouette_score = silhouette_avg  # Update the best silhouette score\n",
    "        best_n_clusters = n_clusters  # Update the best number of clusters\n",
    "\n",
    "print(f\"The optimal number of clusters is {best_n_clusters} with a silhouette score of {best_silhouette_score:.2f}\")  # Print the optimal number of clusters and the corresponding silhouette score\n",
    "\n",
    "# Return above to refit KMeans with the optimal number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions for hierarchical clustering and silhouette score calculation\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "# The linkage function from scipy.cluster.hierarchy is typically used for agglomerative clustering. The method='ward' specifies that the Ward's method is used to minimize the variance within each cluster.\n",
    "linkage_matrix = linkage(Xscaled, method='ward')\n",
    "\n",
    "# Determine the optimal number of clusters using the silhouette score\n",
    "range_n_clusters = list(range(2, 11))  # Define a range of cluster numbers to evaluate, from 2 to 10\n",
    "best_n_clusters_hierarchical = 2  # Initialize the best number of clusters with the minimum value in the range\n",
    "best_silhouette_score_hierarchical = -1  # Initialize the best silhouette score with a very low value\n",
    "\n",
    "for n_clusters in range_n_clusters:  # Iterate over the range of cluster numbers\n",
    "    cluster_labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')  # Retrieve the cluster labels assigned to each data point\n",
    "    silhouette_avg = silhouette_score(Xscaled, cluster_labels)  # Calculate the average silhouette score for the current clustering\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette_score is : {silhouette_avg}\")  # Print the silhouette score for the current number of clusters\n",
    "    if silhouette_avg > best_silhouette_score_hierarchical:  # Check if the current silhouette score is better than the best one found so far\n",
    "        best_silhouette_score_hierarchical = silhouette_avg  # Update the best silhouette score\n",
    "        best_n_clusters_hierarchical = n_clusters  # Update the best number of clusters\n",
    "\n",
    "print(f\"The optimal number of clusters for hierarchical clustering is {best_n_clusters_hierarchical} with a silhouette score of {best_silhouette_score_hierarchical:.2f}\")  # Print the optimal number of clusters and the corresponding silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a part of the dendrogram\n",
    "# Create a figure with a specific size\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Generate a dendrogram from the linkage matrix, truncating the dendrogram to show only the last 30 merged clusters.\n",
    "# p is the number of last merged clusters to display. It controls the number of displayed leaf nodes.  Each leaf may represent a single data point or a cluster of data points, depending on the total number of original data points and the value of p. p is used with the truncate_mode='lastp' parameter.\n",
    "dendrogram(linkage_matrix, truncate_mode='lastp', p=30)\n",
    "\n",
    "# Set the title of the dendrogram plot\n",
    "plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "\n",
    "# Label the x-axis as 'Sample index'\n",
    "plt.xlabel('Sample index')\n",
    "\n",
    "# Label the y-axis as 'Distance'\n",
    "plt.ylabel('Distance')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA  # Import PCA for dimensionality reduction\n",
    "\n",
    "# Fit KMeans with the optimal number of clusters\n",
    "best_n_clusters = 4  # Define the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=best_n_clusters, random_state=42)  # Initialize KMeans with the optimal number of clusters and a random state for reproducibility\n",
    "kmeans.fit(Xscaled)  # Fit KMeans to the scaled data\n",
    "cluster_labels = kmeans.labels_  # Retrieve the cluster labels assigned to each data point\n",
    "\n",
    "# Perform PCA to reduce the data to 2 dimensions for visualization\n",
    "pca = PCA(n_components=2, random_state=42)  # Initialize PCA to reduce the data to 2 dimensions\n",
    "X_pca = pca.fit_transform(Xscaled)  # Fit PCA to the scaled data and transform it\n",
    "X_pca.shape  # Output the shape of the PCA-transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a specific size for the scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a scatter plot of the PCA-reduced data\n",
    "colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan'] \n",
    "\n",
    "# Create a scatter plot with custom colors\n",
    "for cluster in range(best_n_clusters):\n",
    "    # Scatter plot for each cluster\n",
    "    # X_pca[cluster_labels == cluster, 0] represents the PCA-reduced data points for the current cluster on the x-axis\n",
    "    # X_pca[cluster_labels == cluster, 1] represents the PCA-reduced data points for the current cluster on the y-axis\n",
    "    # color=colors[cluster] assigns a unique color to each cluster\n",
    "    # label=f'Cluster {cluster}' assigns a label to each cluster for the legend\n",
    "    # marker='o' specifies the marker style for the scatter plot\n",
    "    # s=20 sets the size of the markers in the scatter plot\n",
    "    plt.scatter(X_pca[cluster_labels == cluster, 0], X_pca[cluster_labels == cluster, 1], \n",
    "                color=colors[cluster], label=f'Cluster {cluster}', marker='o', s=20)\n",
    "\n",
    "# Set the title of the scatter plot\n",
    "plt.title('KMeans Clusters Visualized using PCA')\n",
    "\n",
    "# Label the x-axis as 'Principal Component 1'\n",
    "plt.xlabel('Principal Component 1')\n",
    "\n",
    "# Label the y-axis as 'Principal Component 2'\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
