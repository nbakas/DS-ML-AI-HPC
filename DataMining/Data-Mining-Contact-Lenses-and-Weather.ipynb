{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is a well-known python library for data manipulation and analysis\n",
    "# It is used to load, and analyze data ususally stored in dataframes\n",
    "# The dataframes are tables with rows and columns\n",
    "# The rows are called samples or observations\n",
    "# The columns are called features or variables\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to install the ucimlrepo package\n",
    "# !pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://archive.ics.uci.edu/dataset/58/lenses\n",
    "\n",
    "# ucimlrepo is a python package that allows us to fetch datasets from the UCI Machine Learning Repository\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "lenses = fetch_ucirepo(id=58) \n",
    "  \n",
    "# data is a dictionary with features and targets\n",
    "# We store the features in X and the targets in y\n",
    "X = lenses.data.features \n",
    "y = lenses.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(lenses.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(lenses.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the features\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the targets\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mappings for features\n",
    "# We need these mappings to convert the features (numerical values) to categorical variables\n",
    "feature_mappings = {\n",
    "    \"age\": {1: \"young\", 2: \"pre-presbyopic\", 3: \"presbyopic\"},\n",
    "    \"spectacle_prescription\": {1: \"myope\", 2: \"hypermetrope\"},\n",
    "    \"astigmatic\": {1: \"no\", 2: \"yes\"}\n",
    "}\n",
    "print(feature_mappings)\n",
    "\n",
    "# Define the mapping for the target\n",
    "target_mapping = {\n",
    "    1: \"hard contact lenses\",\n",
    "    2: \"soft contact lenses\",\n",
    "    3: \"no contact lenses\"\n",
    "}\n",
    "print(target_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace feature values with categories\n",
    "Xcat = X.replace(feature_mappings)\n",
    "\n",
    "# Replace target values with categories\n",
    "ycat = y.replace(target_mapping)\n",
    "\n",
    "# Display updated data\n",
    "print(\"Features (Categorical):\")\n",
    "print(Xcat.head())\n",
    "print(\"\\nTargets (Categorical):\")\n",
    "print(ycat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # After running for the first dataset, uncomment the following lines to load the second dataset, and run the code after this\n",
    "# weather = pd.read_csv('https://raw.githubusercontent.com/dataprofessor/data/refs/heads/master/weather-nominal-weka.csv')\n",
    "# # Xcat are the features (all columns except the target, which is 'play')\n",
    "# Xcat = weather.drop(columns=['play'])\n",
    "# # ycat is the target (the column 'play')\n",
    "# ycat = weather['play']\n",
    "# # Make ycat a pandas dataframe (not a series). We need this to have a unified way of handling data with one or more columns\n",
    "# ycat = ycat.to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(Xcat))\n",
    "print(type(ycat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xcat.shape)\n",
    "print(ycat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Iterate over the features\n",
    "for feature in Xcat.columns:\n",
    "    # ax is the plot\n",
    "    ax = sns.countplot(x=feature, data=Xcat)\n",
    "    # Iterate over the patches in the plot. patches are the bars\n",
    "    for p in ax.patches:\n",
    "        # Annotate the height of the bar which is the count of the feature\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='baseline')\n",
    "    plt.show()\n",
    "# Iterate over the targets\n",
    "for target in ycat.columns:\n",
    "    sns.countplot(x=target, data=ycat)\n",
    "    ax = sns.countplot(x=target, data=ycat)\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='baseline')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variables using one-hot encoding\n",
    "XcatEncoded = pd.get_dummies(Xcat)\n",
    "# Display the encoded data\n",
    "XcatEncoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the features and the target\n",
    "import numpy as np\n",
    "# Combine the features and the target\n",
    "data_combined = pd.concat([XcatEncoded, pd.get_dummies(ycat)], axis=1)\n",
    "# Names of the combined data\n",
    "all_variable_names = data_combined.columns\n",
    "# Convert the combined data to a numpy array\n",
    "data_combined = data_combined.to_numpy()\n",
    "print(data_combined)\n",
    "print(all_variable_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the combined data to integers\n",
    "data_combined = data_combined.astype(int)\n",
    "# Display the combined data\n",
    "data_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associations between all features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the accuracy matrix with zeros. Dimensions are the number of features and targets (combined data)\n",
    "accuracy_matrix = np.zeros((len(all_variable_names), len(all_variable_names)))\n",
    "# Iterate over the combined data\n",
    "for i in range(len(all_variable_names)):\n",
    "    # Iterate over the combined data\n",
    "    for j in range(len(all_variable_names)):\n",
    "        # Calculate the accuracy of the association between the two features\n",
    "        # The accuracy is the mean of the equality of the two features, which is 1 if they are equal and 0 if they are not\n",
    "        accuracy_matrix[i, j] = np.mean(data_combined[:, i] == data_combined[:, j])\n",
    "# Display the accuracy matrix\n",
    "accuracy_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the accuracy matrix\n",
    "plt.imshow(accuracy_matrix, cmap='Blues', interpolation='nearest')\n",
    "# Add the variable names to the plot\n",
    "plt.xticks(range(len(all_variable_names)), all_variable_names, rotation=90)\n",
    "plt.yticks(range(len(all_variable_names)), all_variable_names)\n",
    "# Add the accuracy values to the plot\n",
    "for i in range(len(all_variable_names)):\n",
    "    for j in range(len(all_variable_names)):\n",
    "        # Display the accuracy as a percentage\n",
    "        plt.text(j, i, f'{100*accuracy_matrix[i, j]:.0f}%', ha='center', va='center', color='black')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top i,j, pairs with the highest accuracy, except main diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values above the diagonal to 0\n",
    "accuracy_matrix = np.tril(accuracy_matrix, k=0)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the indices and values of the top accuracy pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the accuracy matrix\n",
    "flattened_accuracy_matrix = accuracy_matrix.flatten()\n",
    "flattened_accuracy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices that would sort the flattened accuracy matrix in descending order\n",
    "sorted_indices = np.argsort(flattened_accuracy_matrix)[::-1]\n",
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 2D indices of the sorted values. \n",
    "# This is a tuple of two arrays, one for the row indices and one for the column indices\n",
    "unraveled_indices = np.unravel_index(sorted_indices, accuracy_matrix.shape)\n",
    "unraveled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the indices into a single array\n",
    "stacked_indices = np.dstack(unraveled_indices)\n",
    "stacked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape of stacked_indices is (1, 81, 2) because it is a 3D array \n",
    "# with one \"layer\" or \"batch\" of 81 pairs, each containing two elements. \n",
    "# This is a result of how the np.dstack function works, \n",
    "# which stacks arrays in sequence depth-wise (along the third axis).\n",
    "stacked_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first element from the stacked indices\n",
    "flat_indices = stacked_indices[0]\n",
    "flat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_pairs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pairs = []\n",
    "for i, j in flat_indices:\n",
    "    # Check if the accuracy is between -1 and 1, to avoid the main diagonal\n",
    "    if accuracy_matrix[i, j] > -1 and accuracy_matrix[i, j] < 1:\n",
    "        top_pairs.append((i, j, accuracy_matrix[i, j]))\n",
    "\n",
    "print(top_pairs[:nof_pairs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use top_pairs[0] to get the first pair of indices, \n",
    "# and then we use the first element of the pair to get the row index, \n",
    "# and the second element to get the column index\n",
    "print(f\"the first pair of indices is {top_pairs[0][0]} and {top_pairs[0][1]}\")\n",
    "print(f\"the first variable is\\n{data_combined[:, top_pairs[0][0]]}\")\n",
    "print(f\"and the second variable is\\n{data_combined[:, top_pairs[0][1]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data_combined[:, top_pairs[0][0]] == data_combined[:, top_pairs[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i, j, acc in top_pairs[:nof_pairs]:\n",
    "    print(f\"{all_variable_names[i]} and {all_variable_names[j]} have an accuracy of {acc:.2f}\")\n",
    "    # Calculate the confusion matrix cm\n",
    "    cm = confusion_matrix(data_combined[:, i], data_combined[:, j])\n",
    "    # Display the confusion matrix, using seaborn's heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    # Add the variable names to the plot\n",
    "    plt.xlabel(all_variable_names[j])\n",
    "    plt.ylabel(all_variable_names[i])\n",
    "    # Add the accuracy to the plot as a title\n",
    "    plt.title(f\"Accuracy: {accuracy_score(data_combined[:, i], data_combined[:, j]):.5f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(XcatEncoded, ycat, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "# max_depth is the maximum depth of the tree\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, filled=True, feature_names=XcatEncoded.columns, \n",
    "          class_names=np.unique(ycat.values), fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "tree_rules = export_text(clf, feature_names=list(XcatEncoded.columns))\n",
    "print(tree_rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code3133",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
