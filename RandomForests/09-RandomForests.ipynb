{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from numpy import sum, corrcoef, zeros\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by preparing some synthetic data $Xtr, ytr$. \n",
    "\n",
    "The $ytr$ is the summation of the $Xtr$, plus a random noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = 1_000\n",
    "vars = 10\n",
    "rng = default_rng(seed=0)\n",
    "Xtr = rng.random((obs, vars))\n",
    "ytr = sum(Xtr, axis=1) + (rng.random(obs)-1/2)\n",
    "Xte = rng.random((obs, vars))\n",
    "yte = sum(Xte, axis=1) + (rng.random(obs)-1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with the training of a simple Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(max_depth=10, random_state=0)\n",
    "dtree.fit(Xtr, ytr)\n",
    "\n",
    "# Accuracy\n",
    "pred_tr = dtree.predict(Xtr)\n",
    "acc_tr = corrcoef(ytr,pred_tr)[0,1]\n",
    "print(acc_tr)\n",
    "pred_te = dtree.predict(Xte)\n",
    "acc_te = corrcoef(yte,pred_te)[0,1]\n",
    "print(acc_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a high accuracy in the Train Set, but low in the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with Random Forests. We set the number of trees, and create some random sub-sampling of the columns. We store the indices of the columns in $inds\\_cols$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_trees = 100\n",
    "# we need to keep inds_cols, for train AND later for prediction\n",
    "nof_cols = int(0.7*vars)\n",
    "inds_cols = zeros((nof_trees,nof_cols),dtype=int)\n",
    "for j in range(nof_trees):\n",
    "    rng = default_rng(seed=j+1)\n",
    "    jj = rng.integers(low=0, high=vars, size=nof_cols)\n",
    "    inds_cols[j,:] = jj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we check if the columns have been sampled uniformly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_cols_vec = inds_cols.reshape(nof_trees*nof_cols,1)[:,0]\n",
    "inds_cols_vec\n",
    "counter = Counter(inds_cols_vec)\n",
    "vals = counter.values()\n",
    "keys = counter.keys()\n",
    "plt.bar(keys,vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with the Training of the Random Forest. For each random sampling of the columns that we did previously, we train a decision tree. Furthermore, for each tree, we randomly sub-sampling the rows of the dataset. We store all trained trees in the list $all\\_trees$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_rows = int(0.7*obs)\n",
    "all_trees = []\n",
    "for j in range(nof_trees):\n",
    "    dtree = DecisionTreeRegressor(max_depth=10, random_state=j+1)\n",
    "    rng = default_rng(seed=j+1)\n",
    "    ii = rng.integers(low=0, high=obs, size=nof_rows)\n",
    "    dtree.fit(Xtr[ii,:][:,inds_cols[j,:]], ytr[ii])\n",
    "    all_trees.append(dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we predict for the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr = zeros(obs)\n",
    "pred_te = zeros(obs)\n",
    "for j in range(nof_trees):\n",
    "    j_dtree = all_trees[j]\n",
    "    pred_tr += j_dtree.predict(Xtr[:,inds_cols[j,:]])\n",
    "    pred_te += j_dtree.predict(Xte[:,inds_cols[j,:]])\n",
    "pred_tr /= nof_trees\n",
    "pred_te /= nof_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr = corrcoef(ytr,pred_tr)[0,1]\n",
    "print(acc_tr)\n",
    "acc_te = corrcoef(yte,pred_te)[0,1]\n",
    "print(acc_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy has been vastly improved, and it is similar for the train and test sets, indicating generalization capabilities without over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=nof_trees, max_depth=10, random_state=0)\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# Predict for train and test sets\n",
    "pred_tr_rf = rf.predict(Xtr)\n",
    "pred_te_rf = rf.predict(Xte)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc_tr_rf = corrcoef(ytr, pred_tr_rf)[0,1]\n",
    "print(acc_tr_rf)\n",
    "acc_te_rf = corrcoef(yte, pred_te_rf)[0,1]\n",
    "print(acc_te_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
