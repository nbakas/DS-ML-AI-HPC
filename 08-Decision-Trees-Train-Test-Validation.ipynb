{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the ucimlrepo package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line installs the ucimlrepo package, \n",
    "# which is used to fetch datasets from the UCI Machine Learning Repository\n",
    "# If you have installed the ucimlrepo package, you can skip this line\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# https://archive.ics.uci.edu/dataset/222/bank+marketing\n",
    "# Import the fetch_ucirepo function from the ucimlrepo package\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch the bank marketing dataset from the UCI repository using its ID\n",
    "bank_marketing = fetch_ucirepo(id=222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features (independent variables) from the dataset\n",
    "X = bank_marketing.data.features\n",
    "\n",
    "# Extract the targets (dependent variable) from the dataset\n",
    "y = bank_marketing.data.targets\n",
    "\n",
    "# Get the names of the feature columns\n",
    "features_names = X.columns\n",
    "\n",
    "# Get the name of the target column\n",
    "target_name = y.columns[0]\n",
    "\n",
    "# Print the shape (number of rows and columns) of the features dataframe\n",
    "print(f\"Shape of features: {X.shape}\")\n",
    "\n",
    "# Print the shape (number of rows and columns) of the targets dataframe\n",
    "print(f\"Shape of targets: {y.shape}\")\n",
    "\n",
    "# Print the names of the feature columns\n",
    "print(f\"Features names: {features_names}\")\n",
    "\n",
    "# Print the name of the target column\n",
    "print(f\"Target name: {target_name}\")\n",
    "\n",
    "# Reset the bank_marketing variable to free up memory\n",
    "bank_marketing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the features dataframe to get an overview of the input data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the targets dataframe to get an overview of the target data\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the classes of the target variable\n",
    "# Loop through each unique class in the target variable\n",
    "for i in y[target_name].unique():\n",
    "    # Print the class label and the count of occurrences of that class in the target variable\n",
    "    print(f\"Class {i}: {y[target_name].value_counts()[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values of target variable\n",
    "missing_values = y.isnull().sum()\n",
    "print(f\"Missing values of target variable: {missing_values}\")\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "missing_values = X.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns with missing values from the features dataframe\n",
    "# axis=1 specifies that we are dropping columns (not rows)\n",
    "# dropna() is a pandas function that removes missing values\n",
    "# By default, dropna() removes rows with missing values, \n",
    "# but setting axis=1 changes it to remove columns instead\n",
    "X = X.dropna(axis=1)\n",
    "# Print the shape of the features dataframe after removing the columns with missing values\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data type of the features\n",
    "print(X.dtypes)\n",
    "# print the data type of the target variable\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variables using one-hot encoding\n",
    "# One-hot encoding converts categorical variables into a form that can be provided to ML algorithms to do a better job in prediction.\n",
    "# It creates new binary columns, each representing a unique category in the original column.\n",
    "# For example, if a column 'color' has three categories ['red', 'green', 'blue'], one-hot encoding will create three new columns:\n",
    "# 'color_red', 'color_green', and 'color_blue'. Each row will have a \n",
    "# True in the column corresponding to its original category and False in the others.\n",
    "XcatEncoded = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the names of the columns after one-hot encoding\n",
    "# This will help us understand how the categorical variables have been transformed into binary columns\n",
    "print(XcatEncoded.columns)\n",
    "\n",
    "# Display the first 5 rows of the encoded data to get an overview of the transformed features\n",
    "# This will show us how the original categorical values have been converted into binary columns\n",
    "XcatEncoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy library for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Import the train_test_split function from sklearn to split the data into training, validation, and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the DecisionTreeClassifier class from sklearn to create and train a decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import the accuracy_score function from sklearn to evaluate the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we split the data into a temporary set (X_temp, y_temp) and a test set (X_test, y_test).\n",
    "# The test set will be 20% of the original data, ensuring that the model's performance is evaluated on unseen data.\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(XcatEncoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we split the temporary set (X_temp, y_temp) into training (X_train, y_train) and validation sets (X_val, y_val).\n",
    "# The validation set will be 25% of the temporary set, which corresponds to 20% of the original data.\n",
    "# This ensures that the training set is 60% of the original data, and the validation set is 20% of the original data.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "# Create a decision tree classifier\n",
    "# max_depth is the maximum depth of the tree, it varies from 1 to infinity (default=None)\n",
    "# min_samples_leaf is the minimum number of samples required to be at a leaf node, it varies from 1 to infinity (default=2)\n",
    "# ccp_alpha is the complexity parameter for the cost-complexity pruning, it varies from 0.0 to infinity (default=0.0)\n",
    "# criterion is the function used to measure the quality of a split, it varies between 'gini', 'entropy', 'log_loss' (default='gini')\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=2, min_samples_leaf=2, ccp_alpha=0.0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set, and evaluate the classifier\n",
    "y_pred = clf.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(f\"Training Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Make predictions on the validation set, and evaluate the classifier\n",
    "y_pred = clf.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Make predictions on the test set, and evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the depth of the tree\n",
    "print(f\"Depth of the tree: {clf.get_depth()}\")\n",
    "\n",
    "# Print the minimum number of samples required to be at a leaf node\n",
    "print(f\"Min samples leaf: {clf.min_samples_leaf}\")\n",
    "\n",
    "# Print the complexity parameter for the cost-complexity pruning\n",
    "print(f\"Ccp alpha: {clf.ccp_alpha}\")\n",
    "\n",
    "# Print the function used to measure the quality of a split\n",
    "print(f\"Criterion: {clf.criterion}\")\n",
    "\n",
    "# Print the number of leaves of the tree\n",
    "print(f\"Number of leaves of the tree: {clf.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for visualization\n",
    "from sklearn.tree import plot_tree  # plot_tree is used to visualize the decision tree\n",
    "import matplotlib.pyplot as plt  # matplotlib.pyplot is used for creating static, animated, and interactive visualizations in Python\n",
    "\n",
    "# Check if the number of leaves in the decision tree is less than 10, to avoid plotting a large tree\n",
    "if clf.get_n_leaves() < 10:\n",
    "    # Set the size of the figure for better visualization\n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    # Plot the decision tree with filled nodes, feature names, class names, and specified font size\n",
    "    plot_tree(clf,  # Plot the decision tree\n",
    "              filled=True,  # Fill the nodes with colors\n",
    "              feature_names=XcatEncoded.columns,  # Use the column names of the encoded features\n",
    "              class_names=np.unique(y.values),  # Use the unique values of the target variable as class names\n",
    "              fontsize=10)  # Set the font size for the text in the plot\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "else:\n",
    "    # Print a message indicating that the tree is too large to visualize\n",
    "    print(\"The tree is too large to visualize, number of leaves: \", clf.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the export_text function from sklearn.tree to export the decision tree rules as text\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "# Export the decision tree rules as text, using the feature names from the encoded columns\n",
    "tree_rules = export_text(clf, feature_names=list(XcatEncoded.columns))\n",
    "\n",
    "# Print the exported decision tree rules\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOF_FOLDS = 5 # Number of folds\n",
    "PERCENTAGE_TEST = 0.2 # Percentage of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of classes in the target variable\n",
    "print(f\"Number of instances in the target variable: {y.value_counts()}\")\n",
    "# Print the percentage of each class in the target variable\n",
    "# The normalize=True parameter in value_counts() calculates the relative frequencies of each class\n",
    "print(f\"Percentage of classes in the target variable: {y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(XcatEncoded,  # Split the data into training and testing sets\n",
    "                                                    y,  # The target variable\n",
    "                                                    test_size=PERCENTAGE_TEST,  # The proportion of the dataset to include in the test split\n",
    "                                                    random_state=42)  # Random state for reproducibility, so that if we run the code again, we will get the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KFold from sklearn.model_selection for cross-validation\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KFold with the number of splits, shuffle, and random state\n",
    "kf = KFold(n_splits=NOF_FOLDS,  # Initialize KFold with the number of splits\n",
    "           shuffle=True,  # Shuffle the data before splitting into batches\n",
    "           random_state=42)  # Random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to accumulate accuracy scores\n",
    "average_accuracy_train = 0\n",
    "average_accuracy_val = 0\n",
    "\n",
    "# Loop over each fold in the KFold split\n",
    "all_val_indices = []\n",
    "for fold_index, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Print the number and percentage of instances per class in the training fold\n",
    "    print(f\"Number of instances per class in the training fold: {y_train_fold.value_counts()}\")\n",
    "    print(f\"Percentage of instances per class in the training fold: {y_train_fold.value_counts(normalize=True)}\")\n",
    "\n",
    "    # Print the number and percentage of instances per class in the validation fold\n",
    "    print(f\"Number of instances per class in the validation fold: {y_val_fold.value_counts()}\")\n",
    "    print(f\"Percentage of instances per class in the validation fold: {y_val_fold.value_counts(normalize=True)}\")\n",
    "\n",
    "    # Initialize and train the DecisionTreeClassifier on the training fold\n",
    "    clf = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_leaf=2, ccp_alpha=0.01)\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict and calculate accuracy for the training fold\n",
    "    y_pred_train = clf.predict(X_train_fold)\n",
    "    accuracy_train = accuracy_score(y_train_fold, y_pred_train)\n",
    "    print(f\"Training Accuracy: {accuracy_train:.5f}, fold {fold_index+1} of {NOF_FOLDS}\")\n",
    "\n",
    "    # Predict and calculate accuracy for the validation fold\n",
    "    y_pred_val = clf.predict(X_val_fold)\n",
    "    accuracy_val = accuracy_score(y_val_fold, y_pred_val)\n",
    "    print(f\"Validation Accuracy: {accuracy_val:.5f}, fold {fold_index+1} of {NOF_FOLDS}\")\n",
    "\n",
    "    # Accumulate the accuracy scores for averaging\n",
    "    average_accuracy_train += accuracy_train\n",
    "    average_accuracy_val += accuracy_val\n",
    "\n",
    "    all_val_indices.extend(val_index.tolist())  # Append the validation indices to the list\n",
    "\n",
    "    # Print a separator for readability\n",
    "    print(100*\"-\")\n",
    "\n",
    "# Print a separator for readability\n",
    "print(100*\"-\")\n",
    "# Print the first 10 validation indices after sorting them\n",
    "print(sorted(all_val_indices)[:10])\n",
    "print(100*\"-\")\n",
    "# Print the total number of validation indices and the number of instances in the training set, to check if they are the same\n",
    "print(f\"len(all_val_indices)={len(all_val_indices)}, X_train.shape[0]={X_train.shape[0]}\")\n",
    "print(100*\"-\")\n",
    "\n",
    "# Calculate and print the average training accuracy over all folds\n",
    "average_accuracy_train /= NOF_FOLDS\n",
    "print(f\"Average Training Accuracy: {average_accuracy_train:.5f}\")\n",
    "\n",
    "# Calculate and print the average validation accuracy over all folds\n",
    "average_accuracy_val /= NOF_FOLDS\n",
    "print(f\"Average Cross-validation Accuracy: {average_accuracy_val:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds for cross-validation\n",
    "NOF_FOLDS = 5\n",
    "\n",
    "# Percentage of data to be used for testing\n",
    "PERCENTAGE_TEST = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the data into train and test sets, using stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(XcatEncoded,  # Features to be split\n",
    "                                                    y,  # Target variable\n",
    "                                                    test_size=PERCENTAGE_TEST,  # Proportion of data for testing\n",
    "                                                    random_state=42,  # Seed for reproducibility\n",
    "                                                    stratify=y)  # Ensures class distribution is maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of classes in the target variable\n",
    "print(f\"Number of instances in the training set: {y_train.value_counts()}\")\n",
    "print(f\"Percentage of classes in the training set: {y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Number of instances in the test set: {y_test.value_counts()}\")\n",
    "print(f\"Percentage of classes in the test set: {y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StratifiedKFold for stratified cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Initialize StratifiedKFold with number of splits, shuffle, and random state\n",
    "kf = StratifiedKFold(n_splits=NOF_FOLDS, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize average training accuracy to zero\n",
    "average_accuracy_train = 0\n",
    "# Initialize average validation accuracy to zero\n",
    "average_accuracy_val = 0\n",
    "# Loop over each fold index and split indices for training and validation\n",
    "for fold_index, (train_index, val_index) in enumerate(kf.split(X_train, y_train)): # Note that now (stratedfied) we also use the target variable y_train to split the data\n",
    "    # Split the training data into training and validation folds\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    # Split the target data into training and validation folds\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Print the number of instances per class in the training fold\n",
    "    print(f\"Number of instances per class in the training fold: {y_train_fold.value_counts()}\")\n",
    "    # Print the number of instances per class in the validation fold\n",
    "    print(f\"Number of instances per class in the validation fold: {y_val_fold.value_counts()}\")\n",
    "\n",
    "    # Initialize DecisionTreeClassifier with specified parameters\n",
    "    clf = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_leaf=2, ccp_alpha=0.01)\n",
    "    # Fit the classifier on the training fold\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "    # Predict on the training fold\n",
    "    y_pred_train = clf.predict(X_train_fold)\n",
    "    # Calculate training accuracy\n",
    "    accuracy_train = accuracy_score(y_train_fold, y_pred_train)\n",
    "    # Print training accuracy for the current fold\n",
    "    print(f\"Training Accuracy: {accuracy_train:.5f}, fold {fold_index+1} of {NOF_FOLDS}\")\n",
    "    # Predict on the validation fold\n",
    "    y_pred_val = clf.predict(X_val_fold)\n",
    "    # Calculate validation accuracy\n",
    "    accuracy_val = accuracy_score(y_val_fold, y_pred_val)\n",
    "    # Print validation accuracy for the current fold\n",
    "    print(f\"Validation Accuracy: {accuracy_val:.5f}, fold {fold_index+1} of {NOF_FOLDS}\")\n",
    "    \n",
    "    # Accumulate training accuracy\n",
    "    average_accuracy_train += accuracy_train\n",
    "    # Accumulate validation accuracy\n",
    "    average_accuracy_val += accuracy_val\n",
    "\n",
    "    # Print separator line\n",
    "    print(100*\"-\")\n",
    "\n",
    "# Print separator line\n",
    "print(100*\"-\")\n",
    "# Calculate average training accuracy over all folds\n",
    "average_accuracy_train /= NOF_FOLDS\n",
    "# Print average training accuracy\n",
    "print(f\"Average Training Accuracy: {average_accuracy_train:.5f}\")\n",
    "# Calculate average validation accuracy over all folds\n",
    "average_accuracy_val /= NOF_FOLDS\n",
    "# Print average cross-validation accuracy\n",
    "print(f\"Average Cross-validation Accuracy: {average_accuracy_val:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code3133",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
