{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the ucimlrepo package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line installs the ucimlrepo package, \n",
    "# which is used to fetch datasets from the UCI Machine Learning Repository\n",
    "# If you have installed the ucimlrepo package, you can skip this line\n",
    "# !pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# https://archive.ics.uci.edu/dataset/222/bank+marketing\n",
    "# Import the fetch_ucirepo function from the ucimlrepo package\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch the bank marketing dataset from the UCI repository using its ID\n",
    "bank_marketing = fetch_ucirepo(id=222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features (independent variables) from the dataset\n",
    "X = bank_marketing.data.features\n",
    "\n",
    "# Extract the targets (dependent variable) from the dataset\n",
    "y = bank_marketing.data.targets\n",
    "\n",
    "# Get the names of the feature columns\n",
    "features_names = X.columns\n",
    "\n",
    "# Get the name of the target column\n",
    "target_name = y.columns[0]\n",
    "\n",
    "# Print the shape (number of rows and columns) of the features dataframe\n",
    "print(f\"Shape of features: {X.shape}\")\n",
    "\n",
    "# Print the shape (number of rows and columns) of the targets dataframe\n",
    "print(f\"Shape of targets: {y.shape}\")\n",
    "\n",
    "# Print the names of the feature columns\n",
    "print(f\"Features names: {features_names}\")\n",
    "\n",
    "# Print the name of the target column\n",
    "print(f\"Target name: {target_name}\")\n",
    "\n",
    "# Reset the bank_marketing variable to free up memory\n",
    "bank_marketing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the features dataframe to get an overview of the input data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the targets dataframe to get an overview of the target data\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the classes of the target variable\n",
    "# Loop through each unique class in the target variable\n",
    "for i in y[target_name].unique():\n",
    "    # Print the class label and the count of occurrences of that class in the target variable\n",
    "    print(f\"Class {i}: {y[target_name].value_counts()[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values of target variable\n",
    "missing_values = y.isnull().sum()\n",
    "print(f\"Missing values of target variable: {missing_values}\")\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "missing_values = X.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns with missing values from the features dataframe\n",
    "# axis=1 specifies that we are dropping columns (not rows)\n",
    "# dropna() is a pandas function that removes missing values\n",
    "# By default, dropna() removes rows with missing values, \n",
    "# but setting axis=1 changes it to remove columns instead\n",
    "X = X.dropna(axis=1)\n",
    "# Print the shape of the features dataframe after removing the columns with missing values\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data type of the features\n",
    "print(X.dtypes)\n",
    "# print the data type of the target variable\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variables using one-hot encoding\n",
    "# One-hot encoding converts categorical variables into a form that can be provided to ML algorithms to do a better job in prediction.\n",
    "# It creates new binary columns, each representing a unique category in the original column.\n",
    "# For example, if a column 'color' has three categories ['red', 'green', 'blue'], one-hot encoding will create three new columns:\n",
    "# 'color_red', 'color_green', and 'color_blue'. Each row will have a \n",
    "# True in the column corresponding to its original category and False in the others.\n",
    "XcatEncoded = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the names of the columns after one-hot encoding\n",
    "# This will help us understand how the categorical variables have been transformed into binary columns\n",
    "print(XcatEncoded.columns)\n",
    "\n",
    "# Display the first 5 rows of the encoded data to get an overview of the transformed features\n",
    "# This will show us how the original categorical values have been converted into binary columns\n",
    "XcatEncoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy library for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Import the train_test_split function from sklearn to split the data into training, validation, and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the DecisionTreeClassifier class from sklearn to create and train a decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import the accuracy_score function from sklearn to evaluate the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into a temporary set (X_temp, y_temp) and a test set (X_test, y_test).\n",
    "# The test set will be 20% of the original data, ensuring that the model's performance is evaluated on unseen data.\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(XcatEncoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LogisticRegression class from sklearn to create and train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create an instance of the LogisticRegression class\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the logistic regression model on the temporary training set\n",
    "clf.fit(X_temp, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = clf.predict(X_temp)\n",
    "\n",
    "# Calculate the accuracy of the model on the training set\n",
    "train_accuracy = accuracy_score(y_temp, y_train_pred)\n",
    "\n",
    "# Calculate the precision of the model on the training set\n",
    "train_precision = precision_score(y_temp, y_train_pred, pos_label='yes')\n",
    "\n",
    "# Calculate the recall of the model on the training set\n",
    "train_recall = recall_score(y_temp, y_train_pred, pos_label='yes')\n",
    "\n",
    "# Calculate the F1-score of the model on the training set\n",
    "train_f1 = f1_score(y_temp, y_train_pred, pos_label='yes')\n",
    "\n",
    "# Calculate the ROC AUC score of the model on the training set\n",
    "y_train_prob = clf.predict_proba(X_temp)[:, 1]\n",
    "train_roc_auc = roc_auc_score(y_temp, y_train_prob)\n",
    "\n",
    "# Print all metrics for the training set\n",
    "print(f\"Training Set Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training Set Precision: {train_precision:.4f}\")\n",
    "print(f\"Training Set Recall: {train_recall:.4f}\")\n",
    "print(f\"Training Set F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Training Set ROC AUC: {train_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix function and matplotlib for plotting\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the confusion matrix for the training set\n",
    "train_confusion_matrix = confusion_matrix(y_temp, y_train_pred)\n",
    "\n",
    "# Plot the confusion matrix for the training set\n",
    "plt.figure(figsize=(3, 3))\n",
    "# Plot the confusion matrix for the training set using seaborn heatmap\n",
    "sns.heatmap(train_confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.xlabel('Predicted')  # Label for the x-axis\n",
    "plt.ylabel('Actual')  # Label for the y-axis\n",
    "plt.title('Training Set Confusion Matrix')  # Title of the plot\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the precision of the model on the test set\n",
    "test_precision = precision_score(y_test, y_test_pred, pos_label='yes')\n",
    "\n",
    "# Calculate the recall of the model on the test set\n",
    "test_recall = recall_score(y_test, y_test_pred, pos_label='yes')\n",
    "\n",
    "# Calculate the F1-score of the model on the test set\n",
    "test_f1 = f1_score(y_test, y_test_pred, pos_label='yes')\n",
    "\n",
    "# Calculate the ROC AUC score of the model on the test set\n",
    "y_test_prob = clf.predict_proba(X_test)[:, 1]\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# Print all metrics for the test set\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Set Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Set Recall: {test_recall:.4f}\")\n",
    "print(f\"Test Set F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test Set ROC AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix for the test set\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Plot the confusion matrix for the test set\n",
    "plt.figure(figsize=(3, 3))\n",
    "# Plot the confusion matrix for the test set using seaborn heatmap\n",
    "sns.heatmap(test_confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.xlabel('Predicted')  # Label for the x-axis\n",
    "plt.ylabel('Actual')  # Label for the y-axis\n",
    "plt.title('Test Set Confusion Matrix')  # Title of the plot\n",
    "plt.show()  # Display the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
